# -*- coding: utf-8 -*-
"""Goodreads Analysis and Recommending Books.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YuM77JlY7BBoRoQvrvl-C76Yu0RqaMN_
"""

# importing libraries

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv('/content/drive/My Drive/Colab Notebooks/(ongoing)Goodreads Analysis and Recommending Books/books.csv',error_bad_lines = False)

df.head()

# exploratory data analysis and visualization

# info of dataset
print('Information of Dataset')
print('*'*40)
df.info()

# shape of dataset
print('shape of dataset')
print('*'*20)
print(f'rows : {df.shape[0]}')
print(f'columns : {df.shape[1]}')

# statistical info of dataset
print('statistical info of dataset')
print('*'*20)
df.describe().T

# nan values
print('Missing values\n')
df.isna().sum()

# columns in dataset
df.columns

# dropping unnecessary columns
df.drop(['bookID','isbn','isbn13'], axis=1, inplace=True)

df.head()

# unique values and number of unique values in columns
cols=['title','authors','language_code','publisher']
for vars in cols:
  print(f'number of unique values in {vars} : {df[vars].nunique()}\n')
  print(f'unique values in {vars} : {df[vars].unique()}\n')
  print('*'*50)

df['authors']=df['authors'].replace('J.K. Rowling/Mary GrandPrÃ©' ,'J.K. Rowling')

df.head()

# count of titles
plt.figure(figsize=(20,10))
book_cnt=df['title'].value_counts()[:20]
book_cnt

plt.figure(figsize=(10,10))
sns.barplot(x=book_cnt, y=book_cnt.index)
plt.xlabel('count')



# count of authors
plt.figure(figsize=(20,10))
AUT=df['authors'].value_counts()[:20]
AUT

plt.figure(figsize=(10,10))
sns.barplot(x=AUT, y=AUT.index)
plt.xlabel('count')

# counting of lang
plt.figure(figsize=(20,10))
lang=df['language_code'].value_counts()[:5]
lang

plt.figure(figsize=(5,5))
sns.barplot(x=lang, y=lang.index)
plt.xlabel('count')

# counting of publishers
plt.figure(figsize=(20,10))
publish=df['publisher'].value_counts()[:20]
publish

plt.figure(figsize=(10,10))
sns.barplot(x=publish, y=publish.index)
plt.xlabel('count')

# top 10 books with most rating

most_rated=df.sort_values('ratings_count', ascending=False).set_index('title')[:10]
most_rated
plt.figure(figsize=(10,5))
sns.barplot(x=most_rated['ratings_count'], y=most_rated.index)

df.head()

df['year']=df['publication_date'].apply(lambda x: x.split('/')[-1])

df.head()

# top 10 authors with most number of books
author=df['authors'].value_counts().sort_values(ascending=False)
author[:10]

sns.barplot(x=author[:10], y=author.index[:10])

# english language books
eng_lang=df[df['language_code']=='eng']
eng_lang

# distribution of ratings along the years for PG Wodehouse
aut_wode=df[df['authors']=='P.G. Wodehouse']
plt.figure(figsize=(10,5))
sns.barplot(x=aut_wode['year'].sort_values(), y=aut_wode['average_rating'])
plt.title('Avg rating during course of years')

# distribution of ratings along the years for stephen king
aut_stephen=df[df['authors']=='Stephen King']
plt.figure(figsize=(10,5))
sns.barplot(x=aut_stephen['year'].sort_values(), y=aut_stephen['average_rating'])
plt.title('Avg rating during course of years')



# distribution of ratings along the years for J.K. Rowling
aut_rowling=df[df['authors']=='J.K. Rowling']
plt.figure(figsize=(10,5))
sns.barplot(x=aut_rowling['year'].sort_values(), y=aut_rowling['average_rating'])
plt.title('Avg rating during course of years')

# distribution of ratings along the years for Orson Scott Card 
aut_orson=df[df['authors']=='Orson Scott Card']
plt.figure(figsize=(10,5))
sns.barplot(x=aut_orson['year'].sort_values(), y=aut_orson['average_rating'])
plt.title('Avg rating during course of years')

# distribution of ratings along the years for Agatha Christie
aut_agatha=df[df['authors']=='Agatha Christie']
plt.figure(figsize=(10,5))
sns.barplot(x=aut_agatha['year'].sort_values(), y=aut_agatha['average_rating'])
plt.title('Avg rating during course of years')

# top 10 rated authors with number of books
most_rated_author=df[df['average_rating']>=4.2]
most_rated_author=most_rated_author['authors'].value_counts()[:10]
most_rated_author
sns.barplot(x=most_rated_author,y=most_rated_author.index)

df.head(2)

# distribution of avg rating 
sns.distplot(df['average_rating'])

# distribution of number of pages
sns.distplot(df['  num_pages'])

# distribution of ratings_count
sns.distplot(df['ratings_count'])

# distribution of text_reviews_count
sns.distplot(df['text_reviews_count'])

# distribution of year
sns.distplot(df['year'])

# books with highest rivews
highest_reviews=df.sort_values('text_reviews_count', ascending=False).set_index('title')[:10]
highest_reviews
sns.barplot(x=highest_reviews['text_reviews_count'],y=highest_reviews.index)

df.head(3)

sns.heatmap(df.corr(), annot=True)

# function for rating

def rate(x):
  x=float(x)
  if (0<=x<1):
    return 'between 0 and 1'
  elif (1<=x<2):
    return 'between 1 and 2'
  elif (2<=x<3):
    return 'between 2 and 3'
  elif (3<=x<4):
    return 'between 3 and 4'
  elif (4<=x<=5):
    return'between 4 and 5'
  else:
    return 'beyond world'

df['rating_cat']=df['average_rating'].apply(rate)
df.head()

# rating percetage
rating_pct=df['rating_cat'].value_counts()/len(df)*100
rating_pct

sns.barplot(x=rating_pct, y=rating_pct.index)

# relation between abg rating and number of pages
sns.scatterplot(x=df['average_rating'], y=df['  num_pages'], data=df)

# relation between avg rating and ratings_count
sns.scatterplot(x=df['average_rating'], y=df['ratings_count'], data=df)

# relation between avg rating and text_reviews_count
sns.scatterplot(x=df['average_rating'], y=df['text_reviews_count'], data=df)

df.columns

# boxplot for outliers
num_cols=['average_rating','  num_pages','ratings_count','text_reviews_count']
fig, axes=plt.subplots(2,2, figsize=(20,10))

for i,j in enumerate(num_cols):
  ax=axes[int(i/2), i%2]
  sns.boxplot(df[j], ax=ax)

df['year']=df['year'].astype('int')

df['year'].dtype

df_new=df.copy()

df_new.head()

# predictions

#feature engineering
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

# dummy variables
auth=pd.get_dummies(df_new[['authors']])
tit=pd.get_dummies(df_new[['title']])
lang=pd.get_dummies(df_new[['language_code']])
pub=pd.get_dummies(df_new[['publisher']])
years=pd.get_dummies(df_new[['year']])
rat_cat=pd.get_dummies(df_new[['rating_cat']])

df_new=pd.concat([df_new,auth,tit,lang,pub,years,rat_cat], axis=1)

df_new.drop(['title','authors','language_code','publication_date','publisher','year','rating_cat'], axis=1, inplace=True)

df_new.head(1)

y=df_new['average_rating']
X=df_new.drop('average_rating',1)

df.columns

new_col=['  num_pages','ratings_count', 'text_reviews_count']
X[new_col]=scaler.fit_transform(X[new_col])
X.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
lr=LinearRegression()
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=42)

'''lr.fit(X_train,y_train)
score_lr=lr.score(X_test,y_test)
print(score_lr)'''

'''# random forest
from sklearn.ensemble import RandomForestRegressor
rf=RandomForestRegressor()
rf.fit(X_train,y_train)
score_rf=rf.score(X_test,y_test)
print(score_rf)'''

# recommendation system

df.head()

df_rec=df.copy()

rating_rec=pd.get_dummies(df_rec['rating_cat'])
rating_rec.head()

lang_rec=pd.get_dummies(df_rec['language_code'])
lang_rec.head()

rec_features=pd.concat([rating_rec,lang_rec, df_rec['average_rating'],df_rec['ratings_count'],df_rec['text_reviews_count']], axis=1)
rec_features.head()

from sklearn.preprocessing import MinMaxScaler
mm=MinMaxScaler()

rec_features=mm.fit_transform(rec_features)

# kmeans
from sklearn.cluster import KMeans
g=[]
x=rec_features
for i in range(1,20):
  k_means = KMeans(n_clusters = i, init="k-means++", random_state=42)
  k_means.fit(x)
  g.append(k_means.inertia_)

# ploting elbow
plt.figure(figsize=(15, 10))
plt.plot(range(1,20), g)
plt.title('The Elbow Method')
plt.show()

# KNN

from sklearn.neighbors import NearestNeighbors
clf=NearestNeighbors(n_neighbors=6, algorithm='ball_tree')
clf.fit(rec_features)

distance,id=clf.kneighbors(rec_features)

def rec_system(name):
    book_name = []
    book_id = df_rec[df_rec['title'] == name].index
    book_id = book_id[0]
#     print('book_id', book_id)
    for newid in id[book_id]:
#         print(newid)
        book_name.append(df_rec.loc[newid].title)
#         print(new_data.loc[newid].title)
    return book_name

rec_system('In a Sunburned Country')

